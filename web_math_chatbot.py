import streamlit as st
import google.generativeai as genai
import os
import PIL.Image # ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ìœ„í•œ Pillow ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ì ¸ì˜¤ê¸°

# --- ëª¨ë¸ ì„¤ì • ---
# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ (í‘œì‹œ ì´ë¦„: ì‹¤ì œ ëª¨ë¸ ID)
AVAILABLE_MODELS = {
    "âš¡ï¸ Gemini 2.0 Flash (ë¹ ë¦„, íš¨ìœ¨ì )": "gemini-2.0-flash", # <-- ì‚¬ìš©ìê°€ ìš”ì²­í•œ ëª¨ë¸ ID ë°˜ì˜
    "ğŸš€ Gemini 2.5 Pro Exp (ì‹¤í—˜ìš©, ê³ ì„±ëŠ¥)": "gemini-2.5-pro-exp-03-25",
}
# ê¸°ë³¸ ëª¨ë¸ ì´ë¦„ë„ ì¼ì¹˜ì‹œí‚¤ê±°ë‚˜, ë‹¤ë¥¸ ê¸°ë³¸ê°’ì„ ì›í•˜ì‹œë©´ ìˆ˜ì •í•˜ì„¸ìš”.
DEFAULT_MODEL_NAME = "âš¡ï¸ Gemini 2.0 Flash (ë¹ ë¦„, íš¨ìœ¨ì )" # <-- ê¸°ë³¸ê°’ë„ ì¼ì¹˜ì‹œí‚´

# --- ë¹„ë°€ë²ˆí˜¸ í™•ì¸ í•¨ìˆ˜ ---
def check_password():
    """ë¹„ë°€ë²ˆí˜¸ ì…ë ¥ì°½ì„ í‘œì‹œí•˜ê³  ì…ë ¥ëœ ë¹„ë°€ë²ˆí˜¸ê°€ secretsì— ì €ì¥ëœ ê²ƒê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸"""
    try:
        correct_password = st.secrets.get("APP_PASSWORD", "test1234")
    except Exception:
        correct_password = "test1234"
        if "password_warning_shown" not in st.session_state:
             st.warning("âš ï¸ ë¡œì»¬ í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì„ì‹œ ë¹„ë°€ë²ˆí˜¸ 'test1234'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ë°°í¬ ì‹œì—ëŠ” Streamlit Secretsì— 'APP_PASSWORD'ë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
             st.session_state.password_warning_shown = True

    password_placeholder = st.empty()
    password = password_placeholder.text_input("ğŸ”‘ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password", key="password_input")

    if not password:
        st.info("ì±—ë´‡ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë¹„ë°€ë²ˆí˜¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()

    elif password == correct_password:
        password_placeholder.empty()
        return True
    else:
        st.error("âŒ ë¹„ë°€ë²ˆí˜¸ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.stop()
        return False

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • (ìŠ¤í¬ë¦½íŠ¸ ìµœìƒë‹¨) ---
st.set_page_config(page_title="ìˆ˜í•™ ë¬¸ì œ í’€ì´ ì…”í‹€", page_icon="ğŸš€")

# --- í˜ì´ì§€ ì‹œì‘ ì‹œ ë¹„ë°€ë²ˆí˜¸ í™•ì¸ ---
if check_password():
    # --- ë¹„ë°€ë²ˆí˜¸ ì¸ì¦ ì„±ê³µ í›„ ì•± ë¡œì§ ì‹œì‘ ---
    # st.success("ğŸ”‘ ì¸ì¦ ì„±ê³µ! ì±—ë´‡ì„ ì‹œì‘í•©ë‹ˆë‹¤.", icon="âœ…") # ì„±ê³µ ë©”ì‹œì§€ëŠ” ì ì‹œ ìˆ¨ê¹€

    # --- ì›¹í˜ì´ì§€ ì œëª© ë° ì„¤ëª… ---
    st.title("ğŸ”¢ ìˆ˜í•™ ë¬¸ì œ í’€ì´ ì…”í‹€ ğŸš€")
    st.caption("Gemini AIê°€ ì´ë¯¸ì§€ ì† ìˆ˜í•™ ë¬¸ì œë¥¼ í’€ì–´ë“œë¦½ë‹ˆë‹¤.")

    # --- ëª¨ë¸ ì„ íƒ UI ---
    st.sidebar.header("âš™ï¸ ëª¨ë¸ ì„¤ì •") # ì‚¬ì´ë“œë°”ì— ì„¤ì • ìœ„ì¹˜
    selected_model_display_name = st.sidebar.selectbox(
        "ì‚¬ìš©í•  Gemini ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”:",
        options=list(AVAILABLE_MODELS.keys()), # ë”•ì…”ë„ˆë¦¬ì˜ í‚¤(í‘œì‹œ ì´ë¦„) ëª©ë¡ì„ ì˜µì…˜ìœ¼ë¡œ ì œê³µ
        index=list(AVAILABLE_MODELS.keys()).index(DEFAULT_MODEL_NAME), # ê¸°ë³¸ê°’ ì„¤ì •
        key="selected_model" # session_stateì— ì €ì¥ë  í‚¤
    )
    # ì„ íƒëœ í‘œì‹œ ì´ë¦„ì— í•´ë‹¹í•˜ëŠ” ì‹¤ì œ ëª¨ë¸ ID ê°€ì ¸ì˜¤ê¸°
    selected_model_id = AVAILABLE_MODELS[selected_model_display_name]
    st.sidebar.caption(f"í˜„ì¬ ì„ íƒëœ ëª¨ë¸ ID: `{selected_model_id}`")

    # --- Gemini API ì„¤ì • ---
    API_KEY = st.secrets.get("GEMINI_API_KEY", None)

    if not API_KEY:
        st.error("âš ï¸ ì¤‘ìš”: Streamlit Secrets ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜ì— 'GEMINI_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()

    try:
        genai.configure(api_key=API_KEY)
        # *** ëª¨ë¸ ê°ì²´ ìƒì„±: ì‚¬ìš©ìê°€ ì„ íƒí•œ ëª¨ë¸ ID ì‚¬ìš© ***
        model = genai.GenerativeModel(selected_model_id)
        # print(f"âœ¨ Gemini ëª¨ë¸ ({selected_model_id})ì´ ì„±ê³µì ìœ¼ë¡œ ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤! âœ¨") # í™•ì¸ìš© ë¡œê·¸

    except Exception as e:
        # ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ ì‹œ ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€ ì œê³µ
        st.error(f"ì•—! Gemini ëª¨ë¸({selected_model_id})ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”: {e}")
        st.warning("ì„ íƒí•œ ëª¨ë¸ ì´ë¦„ì´ ì •í™•í•œì§€, API í‚¤ì— í•´ë‹¹ ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop() # ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ ì‹œ ì•± ì‹¤í–‰ ì¤‘ì§€


    # --- Streamlit ì›¹ ì•± ì¸í„°í˜ì´ìŠ¤ ---
    # (ì±„íŒ… ê¸°ë¡, ì´ë¯¸ì§€ ì—…ë¡œë“œ, ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ë¡œì§ì€ ì´ì „ê³¼ ê±°ì˜ ë™ì¼)

    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "uploaded_image" not in st.session_state:
        st.session_state.uploaded_image = None

    # ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    uploaded_file = st.file_uploader("ì—¬ê¸°ì— ìˆ˜í•™ ë¬¸ì œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (PNG, JPG)", type=["png", "jpg", "jpeg"])

    if uploaded_file is not None:
        st.image(uploaded_file, caption="ì—…ë¡œë“œëœ ë¬¸ì œ ì´ë¯¸ì§€", width=300)
        st.session_state.uploaded_image = uploaded_file
        if st.session_state.get("image_processed", False) is False:
          st.info("ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ ì±„íŒ…ì°½ì— í’€ì´ë¥¼ ìš”ì²­í•˜ì„¸ìš” (ì˜ˆ: 'ì´ ë¬¸ì œ í’€ì–´ì¤˜')")
          st.session_state.image_processed = True

    if user_input := st.chat_input(f"{selected_model_display_name}ì—ê²Œ ì§ˆë¬¸í•˜ê¸°..."): # ì…ë ¥ì°½ í”„ë¡¬í”„íŠ¸ ë³€ê²½
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        prompt_parts = []
        gemini_response_text = ""
        current_image_to_process = st.session_state.get("uploaded_image", None)

        # (ì´ë¯¸ì§€ ì²˜ë¦¬ ë° í”„ë¡¬í”„íŠ¸ ìƒì„± ë¡œì§ì€ ë™ì¼)
        if current_image_to_process is not None:
            st.info(f"ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ í¬í•¨í•˜ì—¬ {selected_model_display_name}ì—ê²Œ ì§ˆë¬¸í•©ë‹ˆë‹¤...")
            try:
                img = PIL.Image.open(current_image_to_process)
                prompt_parts = [
                    f"""ë‹¹ì‹ ì€ í•œêµ­ ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì˜ ìˆ˜í•™ ë¬¸ì œ í’€ì´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                    ì£¼ì–´ì§„ ì´ë¯¸ì§€ ì†ì˜ ìˆ˜í•™ ë¬¸ì œë¥¼ ë‹¨ê³„ë³„ë¡œ ìƒì„¸í•˜ê²Œ í’€ì´í•˜ê³ , ìµœì¢… ë‹µì„ ëª…í™•í•˜ê²Œ ì œì‹œí•´ì£¼ì„¸ìš”.
                    ìˆ˜ì‹ì€ LaTeX í˜•ì‹($$...$$ ë˜ëŠ” $$ ... $$)ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

                    ì‚¬ìš©ì ì¶”ê°€ ìš”ì²­/ì§ˆë¬¸: {user_input}
                    """,
                    img
                ]
            except Exception as e:
                st.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                gemini_response_text = "ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
                st.session_state.messages.append({"role": "assistant", "content": gemini_response_text})
        else:
            st.info(f"í…ìŠ¤íŠ¸ ì§ˆë¬¸ìœ¼ë¡œ {selected_model_display_name}ì—ê²Œ ì§ˆë¬¸í•©ë‹ˆë‹¤...")
            prompt_parts = [
                 f"""ë‹¹ì‹ ì€ í•œêµ­ ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì˜ ìˆ˜í•™ ë¬¸ì œ í’€ì´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                 ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”. ìˆ˜í•™ ê´€ë ¨ ì§ˆë¬¸ì´ ì•„ë‹ˆë©´ ê´€ë ¨ ì—†ë‹¤ê³  ë‹µë³€í•´ì£¼ì„¸ìš”.
                 ìˆ˜ì‹ì€ LaTeX í˜•ì‹($$...$$ ë˜ëŠ” $$ ... $$)ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

                 ì§ˆë¬¸: {user_input}
                 """
            ]

        # *** Gemini API í˜¸ì¶œ (ë™ì¼í•œ model ê°ì²´ ì‚¬ìš©) ***
        if not gemini_response_text and prompt_parts:
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                # ìŠ¤í”¼ë„ˆ ë©”ì‹œì§€ì— ëª¨ë¸ ì´ë¦„ í‘œì‹œ
                with st.spinner(f"{selected_model_display_name}ê°€ ì—´ì‹¬íˆ í’€ê³  ìˆì–´ìš”... ğŸ¤”"):
                    try:
                        # *** API í˜¸ì¶œ ë¶€ë¶„ì€ ë³€ê²½ ì—†ìŒ, ì´ë¯¸ model ê°ì²´ê°€ ì„ íƒëœ ëª¨ë¸ë¡œ ìƒì„±ë¨ ***
                        response = model.generate_content(prompt_parts, stream=False)

                        # (ë‹µë³€ ì²˜ë¦¬ ë¡œì§ ë™ì¼)
                        if hasattr(response, 'text'):
                             gemini_response_text = response.text
                        elif response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
                             gemini_response_text = "".join(part.text for part in response.candidates[0].content.parts if hasattr(part, 'text'))
                        else:
                             safety_feedback = response.prompt_feedback
                             block_reason = safety_feedback.block_reason if hasattr(safety_feedback, 'block_reason') else "ì•Œ ìˆ˜ ì—†ìŒ"
                             gemini_response_text = f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì´ìœ : {block_reason})"
                    except Exception as e:
                        st.error(f"Gemini API ({selected_model_id}) í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                        gemini_response_text = "ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ë‹µë³€ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

                message_placeholder.markdown(gemini_response_text)

        if gemini_response_text:
             st.session_state.messages.append({"role": "assistant", "content": gemini_response_text})