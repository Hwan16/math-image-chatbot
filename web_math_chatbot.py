import streamlit as st
import google.generativeai as genai
import os
import io # BytesIO ì‚¬ìš©ì„ ìœ„í•´ ì¶”ê°€
import PIL.Image # ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ìœ„í•œ Pillow ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ì ¸ì˜¤ê¸°

# --- ëª¨ë¸ ì„¤ì • ---
AVAILABLE_MODELS = {
    "âš¡ï¸ Gemini 2.0 Flash (ë¹ ë¦„, íš¨ìœ¨ì )": "gemini-2.0-flash",
    "ğŸš€ Gemini 2.5 Pro Exp (ì‹¤í—˜ìš©, ê³ ì„±ëŠ¥)": "gemini-2.5-pro-exp-03-25",
}
DEFAULT_MODEL_NAME = "âš¡ï¸ Gemini 2.0 Flash (ë¹ ë¦„, íš¨ìœ¨ì )"

# --- ë¹„ë°€ë²ˆí˜¸ í™•ì¸ í•¨ìˆ˜ ---
def check_password():
    # (ë¹„ë°€ë²ˆí˜¸ í™•ì¸ ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼)
    try:
        correct_password = st.secrets.get("APP_PASSWORD", "test1234")
    except Exception:
        correct_password = "test1234"
        if "password_warning_shown" not in st.session_state:
             st.warning("âš ï¸ ë¡œì»¬ í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì„ì‹œ ë¹„ë°€ë²ˆí˜¸ 'test1234'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ë°°í¬ ì‹œì—ëŠ” Streamlit Secretsì— 'APP_PASSWORD'ë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
             st.session_state.password_warning_shown = True
    password_placeholder = st.empty()
    password = password_placeholder.text_input("ğŸ”‘ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password", key="password_input")
    if not password:
        st.info("ì±—ë´‡ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë¹„ë°€ë²ˆí˜¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()
    elif password == correct_password:
        password_placeholder.empty()
        return True
    else:
        st.error("âŒ ë¹„ë°€ë²ˆí˜¸ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.stop()
        return False

# --- Gemini API í˜¸ì¶œ í•¨ìˆ˜ ---
def get_gemini_response(prompt_parts, model_display_name, model_object):
    # (API í˜¸ì¶œ í•¨ìˆ˜ëŠ” ì´ì „ê³¼ ë™ì¼)
    gemini_response_text = ""
    try:
        with st.spinner(f"{model_display_name}ê°€ ë‹µë³€ ìƒì„± ì¤‘... ğŸ¤”"):
            response = model_object.generate_content(prompt_parts, stream=False)
            if hasattr(response, 'text'):
                 gemini_response_text = response.text
            elif response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
                 gemini_response_text = "".join(part.text for part in response.candidates[0].content.parts if hasattr(part, 'text'))
            else:
                 safety_feedback = response.prompt_feedback
                 block_reason = safety_feedback.block_reason if hasattr(safety_feedback, 'block_reason') else "ì•Œ ìˆ˜ ì—†ìŒ"
                 gemini_response_text = f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì´ìœ : {block_reason})"
    except Exception as e:
        st.error(f"Gemini API ({model_object.model_name}) í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        gemini_response_text = "ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ë‹µë³€ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    return gemini_response_text

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="ìˆ˜í•™ ë¬¸ì œ í’€ì´ ì…”í‹€", page_icon="ğŸš€")

# --- í˜ì´ì§€ ì‹œì‘ ì‹œ ë¹„ë°€ë²ˆí˜¸ í™•ì¸ ---
if check_password():
    # --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "current_image_bytes" not in st.session_state:
        st.session_state.current_image_bytes = None
    if "last_processed_image_info" not in st.session_state:
        st.session_state.last_processed_image_info = None

    # --- ì›¹í˜ì´ì§€ UI ---
    st.title("ğŸ”¢ ìˆ˜í•™ ë¬¸ì œ í’€ì´ ì…”í‹€ ğŸš€")
    st.caption("Gemini AIê°€ ì´ë¯¸ì§€ ì† ìˆ˜í•™ ë¬¸ì œë¥¼ í’€ì–´ë“œë¦½ë‹ˆë‹¤.")

    st.markdown("---")
    st.subheader("âš™ï¸ ëª¨ë¸ ì„¤ì •")
    selected_model_display_name = st.selectbox(
        "ì‚¬ìš©í•  Gemini ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”:",
        options=list(AVAILABLE_MODELS.keys()),
        index=list(AVAILABLE_MODELS.keys()).index(DEFAULT_MODEL_NAME),
        key="selected_model"
    )
    selected_model_id = AVAILABLE_MODELS[selected_model_display_name]
    st.caption(f"í˜„ì¬ ì„ íƒëœ ëª¨ë¸ ID: `{selected_model_id}`")
    st.markdown("---")

    # --- Gemini API ì„¤ì • ---
    API_KEY = st.secrets.get("GEMINI_API_KEY", None)
    if not API_KEY:
        st.error("âš ï¸ ì¤‘ìš”: Streamlit Secretsì— 'GEMINI_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
    try:
        genai.configure(api_key=API_KEY)
        model = genai.GenerativeModel(selected_model_id)
    except Exception as e:
        st.error(f"ì•—! Gemini ëª¨ë¸({selected_model_id})ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”: {e}")
        st.warning("ì„ íƒí•œ ëª¨ë¸ ì´ë¦„ì´ ì •í™•í•œì§€, API í‚¤ì— í•´ë‹¹ ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    # --- ì´ë¯¸ì§€ ì—…ë¡œë“œ ì²˜ë¦¬ ---
    uploaded_file = st.file_uploader(
        "ì—¬ê¸°ì— ìˆ˜í•™ ë¬¸ì œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (PNG, JPG)",
        type=["png", "jpg", "jpeg"],
        key="file_uploader"
    )

    # ìƒˆ ì´ë¯¸ì§€ ì—…ë¡œë“œ ê°ì§€ ë° ìë™ ì²˜ë¦¬
    if uploaded_file is not None:
        current_bytes = uploaded_file.getvalue()
        st.session_state.current_image_bytes = current_bytes
        current_image_info = (uploaded_file.name, uploaded_file.size)
        st.image(current_bytes, caption="ì—…ë¡œë“œëœ ë¬¸ì œ ì´ë¯¸ì§€", width=300)

        if current_image_info != st.session_state.get("last_processed_image_info"):
            st.info(f"ìƒˆ ì´ë¯¸ì§€ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. {selected_model_display_name}ì—ê²Œ ìë™ í’€ì´ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤...")
            st.session_state.messages = []

            try:
                img = PIL.Image.open(io.BytesIO(current_bytes))
                # *** ìˆ˜ì •: ìë™ í’€ì´ í”„ë¡¬í”„íŠ¸ì— ìƒˆ í˜•ì‹ ì§€ì¹¨ ì ìš© ***
                auto_solve_prompt = [
                    f"""ë‹¹ì‹ ì€ í•œêµ­ ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì˜ ìˆ˜í•™ ë¬¸ì œ í’€ì´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                    ìµœëŒ€í•œ ìì„¸í•œ í’€ì´ë¥¼ ì œê³µí•˜ì—¬ì„œ, ì²¨ë¶€í•œ ì´ë¯¸ì§€ ë‚´ì˜ ìˆ˜í•™ë¬¸ì œë¥¼ í’€ì–´ì¤˜.
                    ë§Œì•½ ì—¬ëŸ¬ ê°œì˜ ë¬¸ì œê°€ ìˆìœ¼ë©´ ì²«ë²ˆì§¸ë¡œ ë³´ì´ëŠ” ë¬¸ì œë¥¼ í’€ì–´ì¤˜.
                    ìˆ˜ì‹ì€ LaTeX í˜•ì‹($$...$$ ë˜ëŠ” $$ ... $$)ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
                    í•œ ë¬¸ì¥ì´ ëë‚˜ë©´ ë°˜ë“œì‹œ ì¤„ë°”ê¿ˆ(\n)ì„ ì‚¬ìš©í•˜ê³ , LaTeX ìˆ˜ì‹($$...$$ ë˜ëŠ” $$ ... $$)ë„ í•œ ì¤„ì— í•˜ë‚˜ì”©ë§Œ ëª…í™•í•˜ê²Œ í‘œì‹œí•´ì¤˜.
                    """,
                    img
                ]
                gemini_response_text = get_gemini_response(
                    auto_solve_prompt,
                    selected_model_display_name,
                    model
                )
                if gemini_response_text:
                     st.session_state.messages.append({"role": "assistant", "content": gemini_response_text})
                st.session_state.last_processed_image_info = current_image_info

            except Exception as e:
                st.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ë˜ëŠ” ìë™ í’€ì´ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                error_message = f"ì˜¤ë¥˜ ë°œìƒ: {e}"
                if error_message not in [msg.get("content") for msg in st.session_state.messages]:
                    st.session_state.messages.append({"role": "assistant", "content": error_message})
                st.session_state.last_processed_image_info = current_image_info

    # --- ì±„íŒ… ê¸°ë¡ ì¶œë ¥ ---
    st.markdown("### ëŒ€í™” ë‚´ìš©")
    chat_container = st.container(height=400)
    with chat_container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    # --- ì±„íŒ… ì…ë ¥ ì²˜ë¦¬ ---
    if user_input := st.chat_input(f"{selected_model_display_name}ì—ê²Œ ì§ˆë¬¸í•˜ê¸°..."):
        st.session_state.messages.append({"role": "user", "content": user_input})

        prompt_parts = []
        gemini_response_text = ""

        if st.session_state.current_image_bytes is not None:
            try:
                img = PIL.Image.open(io.BytesIO(st.session_state.current_image_bytes))
                # *** ìˆ˜ì •: ì¶”ê°€ ì§ˆë¬¸ í”„ë¡¬í”„íŠ¸ì— ìƒˆ í˜•ì‹ ì§€ì¹¨ ì ìš© ***
                prompt_parts = [
                    f"""ë‹¹ì‹ ì€ í•œêµ­ ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì˜ ìˆ˜í•™ ë¬¸ì œ í’€ì´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                    ì´ì „ì— ì œì‹œëœ ì´ë¯¸ì§€ì™€ í’€ì´ì— ëŒ€í•´ ë‹¤ìŒ ì¶”ê°€ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.
                    ìˆ˜ì‹ì€ LaTeX í˜•ì‹($$...$$ ë˜ëŠ” $$ ... $$)ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
                    í•œ ë¬¸ì¥ì´ ëë‚˜ë©´ ë°˜ë“œì‹œ ì¤„ë°”ê¿ˆ(\n)ì„ ì‚¬ìš©í•˜ê³ , LaTeX ìˆ˜ì‹($$...$$ ë˜ëŠ” $$ ... $$)ë„ í•œ ì¤„ì— í•˜ë‚˜ì”©ë§Œ ëª…í™•í•˜ê²Œ í‘œì‹œí•´ì¤˜.

                    ì¶”ê°€ ì§ˆë¬¸: {user_input}
                    """,
                    img
                ]
            except Exception as e:
                 st.error(f"ì´ë¯¸ì§€ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                 gemini_response_text = "ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ë¡œë“œí•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        else:
            # *** ìˆ˜ì •: í…ìŠ¤íŠ¸ ì§ˆë¬¸ í”„ë¡¬í”„íŠ¸ì— ìƒˆ í˜•ì‹ ì§€ì¹¨ ì ìš© ***
            prompt_parts = [
                 f"""ë‹¹ì‹ ì€ í•œêµ­ ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì˜ ìˆ˜í•™ ë¬¸ì œ í’€ì´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                 ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”. ìˆ˜í•™ ê´€ë ¨ ì§ˆë¬¸ì´ ì•„ë‹ˆë©´ ê´€ë ¨ ì—†ë‹¤ê³  ë‹µë³€í•´ì£¼ì„¸ìš”.
                 ìˆ˜ì‹ì€ LaTeX í˜•ì‹($$...$$ ë˜ëŠ” $$ ... $$)ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
                 í•œ ë¬¸ì¥ì´ ëë‚˜ë©´ ë°˜ë“œì‹œ ì¤„ë°”ê¿ˆ(\n)ì„ ì‚¬ìš©í•˜ê³ , LaTeX ìˆ˜ì‹($$...$$ ë˜ëŠ” $$ ... $$)ë„ í•œ ì¤„ì— í•˜ë‚˜ì”©ë§Œ ëª…í™•í•˜ê²Œ í‘œì‹œí•´ì¤˜.

                 ì§ˆë¬¸: {user_input}
                 """
            ]

        if not gemini_response_text and prompt_parts:
            try:
                gemini_response_text = get_gemini_response(
                    prompt_parts,
                    selected_model_display_name,
                    model
                )
            except Exception as e:
                 st.error(f"ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
                 gemini_response_text = "ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

        if gemini_response_text:
             st.session_state.messages.append({"role": "assistant", "content": gemini_response_text})

        st.rerun()