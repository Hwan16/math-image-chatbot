import streamlit as st
import google.generativeai as genai
import os
import io # BytesIO ì‚¬ìš©ì„ ìœ„í•´ ì¶”ê°€
import PIL.Image # ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ìœ„í•œ Pillow ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ì ¸ì˜¤ê¸°

# --- ëª¨ë¸ ì„¤ì • ---
AVAILABLE_MODELS = {
    "âš¡ï¸ Gemini 2.0 Flash (ë¹ ë¦„, íš¨ìœ¨ì )": "gemini-2.0-flash",
    "ğŸš€ Gemini 2.5 Pro Exp (ì‹¤í—˜ìš©, ê³ ì„±ëŠ¥)": "gemini-2.5-pro-exp-03-25",
}
DEFAULT_MODEL_NAME = "âš¡ï¸ Gemini 2.0 Flash (ë¹ ë¦„, íš¨ìœ¨ì )"

# --- ë¹„ë°€ë²ˆí˜¸ í™•ì¸ í•¨ìˆ˜ ---
def check_password():
    # (ë¹„ë°€ë²ˆí˜¸ í™•ì¸ ë¡œì§ì€ ì´ì „ê³¼ ë™ì¼)
    try:
        correct_password = st.secrets.get("APP_PASSWORD", "test1234")
    except Exception:
        correct_password = "test1234"
        if "password_warning_shown" not in st.session_state:
             st.warning("âš ï¸ ë¡œì»¬ í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì„ì‹œ ë¹„ë°€ë²ˆí˜¸ 'test1234'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ë°°í¬ ì‹œì—ëŠ” Streamlit Secretsì— 'APP_PASSWORD'ë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
             st.session_state.password_warning_shown = True
    password_placeholder = st.empty()
    password = password_placeholder.text_input("ğŸ”‘ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password", key="password_input")
    if not password:
        st.info("ì±—ë´‡ì„ ì‚¬ìš©í•˜ë ¤ë©´ ë¹„ë°€ë²ˆí˜¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()
    elif password == correct_password:
        password_placeholder.empty()
        return True
    else:
        st.error("âŒ ë¹„ë°€ë²ˆí˜¸ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.stop()
        return False

# --- Gemini API í˜¸ì¶œ í•¨ìˆ˜ ---
def get_gemini_response(prompt_parts, model_display_name, model_object):
    # (API í˜¸ì¶œ í•¨ìˆ˜ëŠ” ì´ì „ê³¼ ë™ì¼)
    gemini_response_text = ""
    try:
        # *** ìŠ¤í”¼ë„ˆë¥¼ ì—¬ê¸°ì„œ ê´€ë¦¬í•˜ë„ë¡ ë³€ê²½ ***
        with st.spinner(f"{model_display_name}ê°€ ë‹µë³€ ìƒì„± ì¤‘... ğŸ¤”"):
            response = model_object.generate_content(prompt_parts, stream=False)
            if hasattr(response, 'text'):
                 gemini_response_text = response.text
            elif response.candidates and response.candidates[0].content and response.candidates[0].content.parts:
                 gemini_response_text = "".join(part.text for part in response.candidates[0].content.parts if hasattr(part, 'text'))
            else:
                 safety_feedback = response.prompt_feedback
                 block_reason = safety_feedback.block_reason if hasattr(safety_feedback, 'block_reason') else "ì•Œ ìˆ˜ ì—†ìŒ"
                 gemini_response_text = f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì´ìœ : {block_reason})"
    except Exception as e:
        st.error(f"Gemini API ({model_object.model_name}) í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        gemini_response_text = "ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ë‹µë³€ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    return gemini_response_text

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="ìˆ˜í•™ ë¬¸ì œ í’€ì´ ì…”í‹€", page_icon="ğŸš€")

# --- í˜ì´ì§€ ì‹œì‘ ì‹œ ë¹„ë°€ë²ˆí˜¸ í™•ì¸ ---
if check_password():
    # --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "current_image_bytes" not in st.session_state:
        st.session_state.current_image_bytes = None
    if "last_processed_image_info" not in st.session_state:
        st.session_state.last_processed_image_info = None

    # --- ì›¹í˜ì´ì§€ UI ---
    st.title("ğŸ”¢ ìˆ˜í•™ ë¬¸ì œ í’€ì´ ì…”í‹€ ğŸš€")
    st.caption("Gemini AIê°€ ì´ë¯¸ì§€ ì† ìˆ˜í•™ ë¬¸ì œë¥¼ í’€ì–´ë“œë¦½ë‹ˆë‹¤.")

    st.markdown("---")
    st.subheader("âš™ï¸ ëª¨ë¸ ì„¤ì •")
    selected_model_display_name = st.selectbox(
        "ì‚¬ìš©í•  Gemini ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”:",
        options=list(AVAILABLE_MODELS.keys()),
        index=list(AVAILABLE_MODELS.keys()).index(DEFAULT_MODEL_NAME),
        key="selected_model"
    )
    selected_model_id = AVAILABLE_MODELS[selected_model_display_name]
    st.caption(f"í˜„ì¬ ì„ íƒëœ ëª¨ë¸ ID: `{selected_model_id}`")
    st.markdown("---")

    # --- Gemini API ì„¤ì • ---
    API_KEY = st.secrets.get("GEMINI_API_KEY", None)
    if not API_KEY:
        st.error("âš ï¸ ì¤‘ìš”: Streamlit Secretsì— 'GEMINI_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
    try:
        genai.configure(api_key=API_KEY)
        model = genai.GenerativeModel(selected_model_id)
    except Exception as e:
        st.error(f"ì•—! Gemini ëª¨ë¸({selected_model_id})ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”: {e}")
        st.warning("ì„ íƒí•œ ëª¨ë¸ ì´ë¦„ì´ ì •í™•í•œì§€, API í‚¤ì— í•´ë‹¹ ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    # --- ì´ë¯¸ì§€ ì—…ë¡œë“œ ì²˜ë¦¬ ---
    uploaded_file = st.file_uploader(
        "ì—¬ê¸°ì— ìˆ˜í•™ ë¬¸ì œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (PNG, JPG)",
        type=["png", "jpg", "jpeg"],
        key="file_uploader"
    )

    # ìƒˆ ì´ë¯¸ì§€ ì—…ë¡œë“œ ê°ì§€ ë° ìë™ ì²˜ë¦¬
    if uploaded_file is not None:
        current_bytes = uploaded_file.getvalue()
        st.session_state.current_image_bytes = current_bytes
        current_image_info = (uploaded_file.name, uploaded_file.size)
        st.image(current_bytes, caption="ì—…ë¡œë“œëœ ë¬¸ì œ ì´ë¯¸ì§€", width=300)

        if current_image_info != st.session_state.get("last_processed_image_info"):
            st.info(f"ìƒˆ ì´ë¯¸ì§€ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. {selected_model_display_name}ì—ê²Œ ìë™ í’€ì´ë¥¼ ìš”ì²­í•©ë‹ˆë‹¤...")
            st.session_state.messages = [] # ìƒˆ ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹œ ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™” (ì„ íƒ ì‚¬í•­)

            try:
                img = PIL.Image.open(io.BytesIO(current_bytes))
                auto_solve_prompt = [
                    f"""ë‹¹ì‹ ì€ í•œêµ­ ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì˜ ìˆ˜í•™ ë¬¸ì œ í’€ì´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                    ìµœëŒ€í•œ ìì„¸í•œ í’€ì´ë¥¼ ì œê³µí•˜ì—¬ì„œ, ì²¨ë¶€í•œ ì´ë¯¸ì§€ ë‚´ì˜ ìˆ˜í•™ë¬¸ì œë¥¼ í’€ì–´ì¤˜.
                    ë§Œì•½ ì—¬ëŸ¬ ê°œì˜ ë¬¸ì œê°€ ìˆìœ¼ë©´ ì²«ë²ˆì§¸ë¡œ ë³´ì´ëŠ” ë¬¸ì œë¥¼ í’€ì–´ì¤˜.
                    ìˆ˜ì‹ì€ LaTeX í˜•ì‹($$...$$ ë˜ëŠ” $$ ... $$)ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
                    ë‹µë³€ ì‹œì—ëŠ” í•œêµ­ì–´ ë¬¸ë²• ë° ë„ì–´ì“°ê¸° ê·œì¹™ì„ ì˜ ì§€ì¼œì„œ ëª…í™•í•˜ê³  ì½ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì¤˜. í•œ ì¤„ì—ëŠ” í•œ ë¬¸ì¥ë§Œ ì‘ì„±í•˜ê³ , ë‹¤ìŒ ë¬¸ì¥ì„ ì‹œì‘í•  ë•ŒëŠ” ì¤„ë°”ê¿ˆ(\n)ì„ ì‚¬ìš©í•´ì¤˜.
                    """,
                    img
                ]

                # *** ìˆ˜ì •: API í˜¸ì¶œ ë° ê²°ê³¼ ë°›ê¸° (ì—¬ê¸°ì„œ ë°”ë¡œ í‘œì‹œí•˜ì§€ ì•ŠìŒ) ***
                gemini_response_text = get_gemini_response(
                    auto_solve_prompt,
                    selected_model_display_name,
                    model
                )

                # *** ìˆ˜ì •: ë°›ì€ ê²°ê³¼ë¥¼ ì„¸ì…˜ ìƒíƒœ ë©”ì‹œì§€ì—ë§Œ ì¶”ê°€ ***
                if gemini_response_text: # ì‘ë‹µì´ ìˆì„ ê²½ìš°ì—ë§Œ ì¶”ê°€
                     st.session_state.messages.append({"role": "assistant", "content": gemini_response_text})

                st.session_state.last_processed_image_info = current_image_info

            except Exception as e:
                st.error(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ë˜ëŠ” ìë™ í’€ì´ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                # ì˜¤ë¥˜ ë©”ì‹œì§€ë„ ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€ ê°€ëŠ¥
                error_message = f"ì˜¤ë¥˜ ë°œìƒ: {e}"
                if error_message not in [msg.get("content") for msg in st.session_state.messages]: # ì¤‘ë³µ ë°©ì§€
                    st.session_state.messages.append({"role": "assistant", "content": error_message})
                st.session_state.last_processed_image_info = current_image_info # ì˜¤ë¥˜ ì‹œì—ë„ ì²˜ë¦¬ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼

    # --- ì±„íŒ… ê¸°ë¡ ì¶œë ¥ (ì´ì œ ì—¬ê¸°ì„œ ëª¨ë“  ë©”ì‹œì§€ê°€ í•œ ë²ˆì”© í‘œì‹œë¨) ---
    st.markdown("### ëŒ€í™” ë‚´ìš©") # ì œëª© ì¶”ê°€
    chat_container = st.container(height=400) # ìŠ¤í¬ë¡¤ ê°€ëŠ¥í•œ ì»¨í…Œì´ë„ˆ ì‚¬ìš©
    with chat_container:
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    # --- ì±„íŒ… ì…ë ¥ ì²˜ë¦¬ (ì¶”ê°€ ì§ˆë¬¸ ë˜ëŠ” í…ìŠ¤íŠ¸ ì§ˆë¬¸) ---
    if user_input := st.chat_input(f"{selected_model_display_name}ì—ê²Œ ì§ˆë¬¸í•˜ê¸°..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€ (í™”ë©´ í‘œì‹œëŠ” ì•„ë˜ ì±„íŒ… ê¸°ë¡ ì¶œë ¥ ë£¨í”„ì—ì„œ ì²˜ë¦¬)
        st.session_state.messages.append({"role": "user", "content": user_input})

        # *** ì¶”ê°€: ì‚¬ìš©ì ì…ë ¥ í›„ ì¦‰ì‹œ ì¬ì‹¤í–‰í•˜ì—¬ ì…ë ¥ í•„ë“œ ë¹„ìš°ê³  ë©”ì‹œì§€ í‘œì‹œ ***
        # st.rerun() # ì´ ë°©ë²•ë³´ë‹¤ëŠ” ì•„ë˜ ë°©ì‹ì´ ë” ìì—°ìŠ¤ëŸ¬ìš¸ ìˆ˜ ìˆìŒ

        # (ì´í›„ ë¡œì§ì€ API í˜¸ì¶œ ë° ê²°ê³¼ ë©”ì‹œì§€ ì¶”ê°€)
        prompt_parts = []
        gemini_response_text = ""

        if st.session_state.current_image_bytes is not None:
            # st.info(f"ì—…ë¡œë“œëœ ì´ë¯¸ì§€ì— ëŒ€í•´ {selected_model_display_name}ì—ê²Œ ì¶”ê°€ ì§ˆë¬¸í•©ë‹ˆë‹¤...") # info ë©”ì‹œì§€ ì œê±° (ì„ íƒ ì‚¬í•­)
            try:
                img = PIL.Image.open(io.BytesIO(st.session_state.current_image_bytes))
                prompt_parts = [
                    f"""ë‹¹ì‹ ì€ í•œêµ­ ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì˜ ìˆ˜í•™ ë¬¸ì œ í’€ì´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                    ì´ì „ì— ì œì‹œëœ ì´ë¯¸ì§€ì™€ í’€ì´ì— ëŒ€í•´ ë‹¤ìŒ ì¶”ê°€ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”.
                    ìˆ˜ì‹ì€ LaTeX í˜•ì‹($$...$$ ë˜ëŠ” $$ ... $$)ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
                    ë‹µë³€ ì‹œì—ëŠ” í•œêµ­ì–´ ë¬¸ë²• ë° ë„ì–´ì“°ê¸° ê·œì¹™ì„ ì˜ ì§€ì¼œì„œ ëª…í™•í•˜ê³  ì½ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì¤˜. í•œ ì¤„ì—ëŠ” í•œ ë¬¸ì¥ë§Œ ì‘ì„±í•˜ê³ , ë‹¤ìŒ ë¬¸ì¥ì„ ì‹œì‘í•  ë•ŒëŠ” ì¤„ë°”ê¿ˆ(\n)ì„ ì‚¬ìš©í•´ì¤˜.

                    ì¶”ê°€ ì§ˆë¬¸: {user_input}
                    """,
                    img
                ]
            except Exception as e:
                 st.error(f"ì´ë¯¸ì§€ ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                 gemini_response_text = "ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ë¡œë“œí•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        else:
            # st.info(f"í…ìŠ¤íŠ¸ ì§ˆë¬¸ìœ¼ë¡œ {selected_model_display_name}ì—ê²Œ ì§ˆë¬¸í•©ë‹ˆë‹¤...") # info ë©”ì‹œì§€ ì œê±° (ì„ íƒ ì‚¬í•­)
            prompt_parts = [
                 f"""ë‹¹ì‹ ì€ í•œêµ­ ê³ ë“±í•™ìƒ ìˆ˜ì¤€ì˜ ìˆ˜í•™ ë¬¸ì œ í’€ì´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
                 ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”. ìˆ˜í•™ ê´€ë ¨ ì§ˆë¬¸ì´ ì•„ë‹ˆë©´ ê´€ë ¨ ì—†ë‹¤ê³  ë‹µë³€í•´ì£¼ì„¸ìš”.
                 ìˆ˜ì‹ì€ LaTeX í˜•ì‹($$...$$ ë˜ëŠ” $$ ... $$)ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
                 ë‹µë³€ ì‹œì—ëŠ” í•œêµ­ì–´ ë¬¸ë²• ë° ë„ì–´ì“°ê¸° ê·œì¹™ì„ ì˜ ì§€ì¼œì„œ ëª…í™•í•˜ê³  ì½ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì¤˜. í•œ ì¤„ì—ëŠ” í•œ ë¬¸ì¥ë§Œ ì‘ì„±í•˜ê³ , ë‹¤ìŒ ë¬¸ì¥ì„ ì‹œì‘í•  ë•ŒëŠ” ì¤„ë°”ê¿ˆ(\n)ì„ ì‚¬ìš©í•´ì¤˜.

                 ì§ˆë¬¸: {user_input}
                 """
            ]

        if not gemini_response_text and prompt_parts:
            # *** ìˆ˜ì •: API í˜¸ì¶œ ë¶€ë¶„ì„ try ë¸”ë¡ìœ¼ë¡œ ê°ì‹¸ê³ , ìŠ¤í”¼ë„ˆ ìœ„ì¹˜ ì¡°ì • ***
            try:
                # API í˜¸ì¶œ í•¨ìˆ˜ ì‚¬ìš© (ìŠ¤í”¼ë„ˆëŠ” í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì²˜ë¦¬)
                gemini_response_text = get_gemini_response(
                    prompt_parts,
                    selected_model_display_name,
                    model
                )
            except Exception as e: # í˜¹ì‹œ ëª¨ë¥¼ ì¶”ê°€ ì˜ˆì™¸ ì²˜ë¦¬
                 st.error(f"ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
                 gemini_response_text = "ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

        # ì‘ë‹µ ë©”ì‹œì§€ ì¶”ê°€ (í™”ë©´ í‘œì‹œëŠ” ë‹¤ìŒ rerun ì‹œ ì±„íŒ… ê¸°ë¡ ì¶œë ¥ ë£¨í”„ì—ì„œ ì²˜ë¦¬)
        if gemini_response_text:
             st.session_state.messages.append({"role": "assistant", "content": gemini_response_text})

        # *** ì¶”ê°€: ë©”ì‹œì§€ ì¶”ê°€ í›„ ìŠ¤í¬ë¦½íŠ¸ ì¬ì‹¤í–‰ ìš”ì²­í•˜ì—¬ í™”ë©´ ì¦‰ì‹œ ì—…ë°ì´íŠ¸ ***
        st.rerun()